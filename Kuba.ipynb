{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import shap\n",
    "from sklearn.inspection import permutation_importance\n",
    "from typing import Tuple, Union, Optional, Callable\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "from importlib import reload\n",
    "import constants\n",
    "import data_utils\n",
    "import models\n",
    "import training_and_selection\n",
    "import plot_accuracies\n",
    "import explanation_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(constants)\n",
    "reload(models)\n",
    "from constants import (\n",
    "    SEED,\n",
    "    NUM_SPLITS,\n",
    "    INITIAL_CUTOFF,\n",
    "    TOP,\n",
    "    TARGET,\n",
    "    MODEL_ACCURACIES_PATH,\n",
    "    FILTERED_MODEL_ACCURACIES_PATH,\n",
    "    TIME_LIMIT,\n",
    "    TIME_LIMIT_CROSS_VALIDATION,\n",
    "    RASHOMON_SETS_PATH,\n",
    "    INITIAL_ACCURACIES_PATH,\n",
    "    CHECKPOINT_PATH,\n",
    ")\n",
    "from models import MODELS, HYPERPARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krzaq/xai/XAI-team-project/data_utils.py:20: DtypeWarning: Columns (4,11,12,16,17,18,19,20,40,41,42,43,44,45,52,53,54,55,56,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,108,110) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dataset = pd.read_csv(\"SpeedDating.csv\", index_col=0)\n"
     ]
    }
   ],
   "source": [
    "reload(data_utils)\n",
    "from data_utils import get_dataset\n",
    "\n",
    "X, y = get_dataset()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=(SEED+1))\n",
    "BASELINE = np.sum(y == 1) / np.sum(y == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVMClassifier 321\n",
      "TabRClassifier 293\n",
      "XGBClassifier 289\n",
      "SVMClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "720it [00:00, 286545.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TabRClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "288it [00:00, 660448.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "288it [00:00, 784389.32it/s]\n",
      "48it [00:00, 418558.40it/s]\n",
      "43it [00:00, 430441.70it/s]\n",
      "43it [00:00, 406205.12it/s]\n"
     ]
    }
   ],
   "source": [
    "reload(constants)\n",
    "reload(training_and_selection)\n",
    "from training_and_selection import get_rashomon_sets\n",
    "\n",
    "rashomon_sets_params = get_rashomon_sets(\n",
    "    models=MODELS,\n",
    "    hyperparameters=HYPERPARAMETERS,\n",
    "    X=X,\n",
    "    y=y,\n",
    "    initial_cutoff=0.15,\n",
    "    top=0.04,\n",
    "    initial_time_limit=50,\n",
    "    cross_validation_time_limit=60,\n",
    "    initial_path='results/initial_grid_search.csv',\n",
    "    cross_validation_path='results/cross_validation_results.csv',\n",
    ")\n",
    "pickle.dump(rashomon_sets_params, open(RASHOMON_SETS_PATH, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "reload(training_and_selection)\n",
    "reload(explanation_utils)\n",
    "from typing import Any, Dict\n",
    "from explanation_utils import EXPLANATION_FUNCS\n",
    "from models import TabRClassifier\n",
    "from training_and_selection import release_model_vram\n",
    "\n",
    "\n",
    "CHECKPOINT_PATH = 'checkpoints'\n",
    "\n",
    "def get_model(model_class, kwargs, X_train, y_train):\n",
    "    save_path = f'{CHECKPOINT_PATH}/{model_class.__name__}/{str(kwargs)}.pickle'\n",
    "    if os.path.exists(save_path):\n",
    "        with open(save_path, 'rb') as file:\n",
    "            model = pickle.load(file)\n",
    "        return model\n",
    "\n",
    "    if model_class.__name__ == 'SVMClassifier':\n",
    "        model = model_class(probability=True, **kwargs)\n",
    "    else:\n",
    "        model = model_class(**kwargs)\n",
    "    model.fit(X_train, y_train)\n",
    "    # if model_class.__name__ == 'TabRClassifier':\n",
    "    #     model.network = model.network.to('cpu')\n",
    "    #     model.X_train = model.X_train.to('cpu')\n",
    "    #     model.y_train = model.y_train.to('cpu')\n",
    "    #     model.train_indices = model.train_indices.to('cpu')\n",
    "    #     model.device_name = 'cpu'\n",
    "    #     torch.cuda.empty_cache()\n",
    "    if model_class.__name__ != 'TabRClassifier':\n",
    "        with open(save_path, 'wb') as file:\n",
    "            pickle.dump(model, file)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def run_all_explanations(\n",
    "        models,\n",
    "        rashomon_sets_params,\n",
    "        explanation_funcs: Dict[str, Callable],\n",
    "        X_train,\n",
    "        y_train,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        plot=False\n",
    "    ):\n",
    "    # rashomon_sets = {}\n",
    "    # rashomon_sets_acc_lower_bounds = {}\n",
    "    explanations = {name: dict() for name in explanation_funcs.keys()}\n",
    "\n",
    "    for model_class in models:\n",
    "        for kwargs in tqdm(rashomon_sets_params[model_class.__name__]):\n",
    "        # save_path = f'checkpoints/{model_class.__name__}'\n",
    "        # if not os.path.exists(save_path):\n",
    "        #     os.mkdir(save_path)\n",
    "\n",
    "        # rashomon_sets[model_class.__name__] = []\n",
    "        # accuracies[model_class.__name__] = []\n",
    "            model = get_model(model_class, kwargs, X_train, y_train)\n",
    "            model_idx = model_class.__name__, str(kwargs)\n",
    "            for name, explain_func in explanation_funcs.items():\n",
    "                expl = explain_func(model, X_test, y_test, plot=plot)\n",
    "                explanations[name][model_idx] = expl\n",
    "                # if model_class.__name__ == 'SVMClassifier':\n",
    "                #     model = model_class(probability=True, **kwargs)\n",
    "                # else:\n",
    "                #     model = model_class(**kwargs)\n",
    "                # model.fit(X_train, y_train)\n",
    "                # acc = np.mean(model.predict(X_test) == np.array(y_test))\n",
    "                # accuracies[model_class.__name__].append(acc)\n",
    "                # if model_class.__name__ == 'TabRClassifier':\n",
    "                #     del model\n",
    "                #     gc.collect()\n",
    "                #     torch.cuda.empty_cache()\n",
    "                # with open(f'{save_path}/{str(kwargs)}.pickle', 'wb') as file:\n",
    "                #     pickle.dump(model, file)\n",
    "                # rashomon_sets[model_class.__name__].append(model)\n",
    "            release_model_vram(model)\n",
    "        # rashomon_sets_acc_lower_bounds[model_class.__name__] = min(accuracies[model_class.__name__])\n",
    "    return explanations\n",
    "\n",
    "explanations = run_all_explanations(MODELS, rashomon_sets_params, EXPLANATION_FUNCS, X_train, y_train, X_test, y_test, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bae037338a64336aaf814674896e06c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:05<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Predictive Positive Rate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m reload(explanation_utils)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexplanation_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m run_all_explanations\n\u001b[0;32m----> 5\u001b[0m explanations \u001b[38;5;241m=\u001b[39m \u001b[43mrun_all_explanations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODELS\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrashomon_sets_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/xai/XAI-team-project/explanation_utils.py:146\u001b[0m, in \u001b[0;36mrun_all_explanations\u001b[0;34m(models, rashomon_sets_params, X_train, y_train, X_test, y_test, explanation_funcs, plot)\u001b[0m\n\u001b[1;32m    144\u001b[0m model_idx \u001b[38;5;241m=\u001b[39m model_class\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;28mstr\u001b[39m(kwargs)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, explain_func \u001b[38;5;129;01min\u001b[39;00m explanation_funcs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 146\u001b[0m     expl \u001b[38;5;241m=\u001b[39m \u001b[43mexplain_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m     explanations[name][model_idx] \u001b[38;5;241m=\u001b[39m expl\n\u001b[1;32m    148\u001b[0m release_model_vram(model)\n",
      "File \u001b[0;32m~/xai/XAI-team-project/explanation_utils.py:56\u001b[0m, in \u001b[0;36mperformance_metrics\u001b[0;34m(model, X_test, y_test, plot)\u001b[0m\n\u001b[1;32m     54\u001b[0m     metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDemographic Parity\u001b[39m\u001b[38;5;124m\"\u001b[39m][feature_name] \u001b[38;5;241m=\u001b[39m demographic_parity\n\u001b[1;32m     55\u001b[0m     metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEqual Opportunity\u001b[39m\u001b[38;5;124m\"\u001b[39m][feature_name] \u001b[38;5;241m=\u001b[39m equal_opportunity\n\u001b[0;32m---> 56\u001b[0m     \u001b[43mmetrics\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPredictive Positive Rate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[feature_name] \u001b[38;5;241m=\u001b[39m predictive_positive_rate\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m metrics\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Predictive Positive Rate'"
     ]
    }
   ],
   "source": [
    "reload(constants)\n",
    "reload(explanation_utils)\n",
    "from explanation_utils import run_all_explanations\n",
    "\n",
    "explanations = run_all_explanations(MODELS[::-1], rashomon_sets_params, X_train, y_train, X_test, y_test, plot=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import EXPLANATIONS_PATH\n",
    "\n",
    "\n",
    "with open(EXPLANATIONS_PATH, 'rb') as file:\n",
    "    explanations = pickle.load(file)\n",
    "\n",
    "explanations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
