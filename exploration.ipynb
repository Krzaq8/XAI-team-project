{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "# imports\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sympy.stats.rv import probability\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler # To preprocess data for SVM - greatly improves performance\n",
    "from sklearn.svm import SVC\n",
    "from pytorch_tabr import TabRClassifier as TabRClassifier_\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import shap\n",
    "from sklearn.inspection import permutation_importance\n",
    "from itertools import product\n",
    "from typing import Tuple, Union, Optional, Callable\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import csv\n",
    "from pathlib import Path"
   ],
   "metadata": {
    "id": "mzX1wFJAONFQ",
    "ExecuteTime": {
     "end_time": "2025-02-01T17:58:18.645965Z",
     "start_time": "2025-02-01T17:58:02.218353Z"
    }
   },
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T17:58:18.676083Z",
     "start_time": "2025-02-01T17:58:18.661124Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import signal\n",
    "from contextlib import contextmanager\n",
    "\n",
    "class TimeoutException(Exception): pass\n",
    "\n",
    "@contextmanager\n",
    "def time_limit(seconds):\n",
    "    def signal_handler(signum, frame):\n",
    "        raise TimeoutException(\"Timed out!\")\n",
    "    signal.signal(signal.SIGALRM, signal_handler)\n",
    "    signal.alarm(seconds)\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        signal.alarm(0)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T17:58:18.691044Z",
     "start_time": "2025-02-01T17:58:18.681070Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def SVMClassifier(**hyperparams):\n",
    "    return make_pipeline(StandardScaler(), SVC(**hyperparams))"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T17:58:18.707001Z",
     "start_time": "2025-02-01T17:58:18.699025Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TabRClassifier(TabRClassifier_):\n",
    "    def __init__(self, **kwargs):\n",
    "        # selection_function_name=\"sparsemax\",\n",
    "        # context_dropout=0.5,\n",
    "        # context_sample_size=2000,\n",
    "        # num_embeddings={\"type\": \"PLREmbeddings\", \"n_frequencies\": 32, \"frequency_scale\": 32, \"d_embedding\": 32, \"lite\": False},\n",
    "        super().__init__(**kwargs)\n",
    "        self.type_embeddings=\"one-hot\"\n",
    "        self.device_name=\"cpu\"\n",
    "        self.optimizer_params={\"lr\": 2e-4}\n",
    "        \n",
    "    def fit(\n",
    "        self,\n",
    "        X_train: pd.DataFrame,\n",
    "        y_train: pd.DataFrame,\n",
    "        **kwargs\n",
    "    ) -> None:\n",
    "        super().fit(X_train=X_train.values, y_train=y_train.values,\n",
    "                    max_epochs=1, batch_size=25, **kwargs)\n",
    "        \n",
    "    def predict(self, X: pd.DataFrame):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            return super().predict_proba(X=X.values)\n",
    "        else:\n",
    "            return super().predict_proba(X=X)\n",
    "    \n",
    "    def predict_proba(self, X: pd.DataFrame):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            return super().predict_proba(X=X.values)\n",
    "        else:\n",
    "            return super().predict_proba(X=X)\n",
    "        "
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "# constants\n",
    "SEED = 42\n",
    "NUM_SPLITS = 5\n",
    "INITIAL_CUTOFF = 0.75\n",
    "TOP = 0.5\n",
    "TARGET = \"decision\"\n",
    "MODELS = [SVMClassifier, TabRClassifier, XGBClassifier]\n",
    "MODEL_ACCURACIES_PATH = 'model_accuracies.csv'\n",
    "FILTERED_MODEL_ACCURACIES_PATH = 'filtered_model_accuracies.csv'\n",
    "TIME_LIMIT = 12\n",
    "TIME_LIMIT_CROSS_VALIDATION = 12\n",
    "\n",
    "XGBCLASSIFIER_HYPERPARAMETERS = {\n",
    "    \"max_depth\": [3, 6],\n",
    "    \"min_child_weight\": [1, 4],\n",
    "}\n",
    "\n",
    "SVMCLASSIFIER_HYPERPARAMETERS = {\n",
    "    \"kernel\": ['poly'],\n",
    "    'degree': [1, 2]\n",
    "    # \"device\": [\"cuda\"],\n",
    "}\n",
    "\n",
    "TABRCLASSIFIER_HYPERPARAMETERS = {\n",
    "   \"d_main\": [12, 36],\n",
    "    \"d_multiplier\": [1.5, 2],\n",
    "    \"seed\": [SEED]\n",
    "}\n",
    "\n",
    "HYPERPARAMETERS = {\n",
    "    XGBClassifier.__name__ : XGBCLASSIFIER_HYPERPARAMETERS,\n",
    "    SVMClassifier.__name__ : SVMCLASSIFIER_HYPERPARAMETERS,\n",
    "    TabRClassifier.__name__ : TABRCLASSIFIER_HYPERPARAMETERS\n",
    "}"
   ],
   "metadata": {
    "id": "r4lGdgRVRMM5",
    "ExecuteTime": {
     "end_time": "2025-02-01T17:58:18.722958Z",
     "start_time": "2025-02-01T17:58:18.712986Z"
    }
   },
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "def one_hot_encode(df, features):\n",
    "    for feature in features:\n",
    "        dummies = pd.get_dummies(df.loc[:, feature], prefix=feature)\n",
    "        df = pd.concat([df, dummies], axis=1)\n",
    "        df = df.drop(feature, axis=1)\n",
    "    return df"
   ],
   "metadata": {
    "id": "1dy8AeieTKI2",
    "ExecuteTime": {
     "end_time": "2025-02-01T17:58:18.738947Z",
     "start_time": "2025-02-01T17:58:18.727945Z"
    }
   },
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iGaslg9IB3oc",
    "outputId": "7eeb95d1-73ae-4231-9873-3c6bd3956e8e",
    "ExecuteTime": {
     "end_time": "2025-02-01T17:58:20.706559Z",
     "start_time": "2025-02-01T17:58:19.407656Z"
    }
   },
   "source": [
    "# load dataset\n",
    "dataset = pd.read_csv(\"SpeedDating.csv\", index_col=0)\n",
    "\n",
    "# remove redundant columns\n",
    "subset = ['gender', 'age', 'age_o', 'race', 'race_o', 'importance_same_race', 'importance_same_religion',\n",
    "          'pref_o_attractive', 'pref_o_sincere', 'pref_o_intelligence',\n",
    "          'pref_o_funny', 'pref_o_ambitious', 'pref_o_shared_interests', 'attractive_o', 'sinsere_o', 'intelligence_o', 'funny_o',\n",
    "          'ambitous_o', 'shared_interests_o', 'attractive_important', 'sincere_important', 'intellicence_important', 'funny_important', 'ambtition_important',\n",
    "          'shared_interests_important', 'attractive', 'sincere', 'intelligence', 'funny', 'ambition', 'attractive_partner', 'sincere_partner',\n",
    "          'intelligence_partner', 'funny_partner', 'ambition_partner', 'shared_interests_partner',\n",
    "          'sports', 'tvsports', 'exercise', 'dining', 'museums', 'art', 'hiking', 'gaming', 'clubbing', 'reading', 'tv', 'theater', 'movies', 'concerts',\n",
    "          'music', 'shopping', 'yoga',\n",
    "          'interests_correlate', 'expected_happy_with_sd_people', 'expected_num_matches', 'expected_num_interested_in_me',\n",
    "          'like', 'guess_prob_liked', 'decision']\n",
    "\n",
    "dataset = dataset.loc[:, subset]\n",
    "dataset.loc[:, 'gender'] = (dataset.loc[:, 'gender'] == 'female') # one hot encode gender\n",
    "dataset = one_hot_encode(dataset, ['race', 'race_o'])\n",
    "dataset = dataset.apply(pd.to_numeric, errors='coerce', axis=1)\n",
    "dataset = dataset.fillna(dataset.mean())\n",
    "print(dataset.head())\n",
    "X, y = dataset.loc[:, dataset.columns != TARGET], dataset.loc[:, TARGET]\n",
    "BASELINE = np.sum(y == 1) / np.sum(y == 0)\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mracz\\AppData\\Local\\Temp\\ipykernel_25588\\3974884003.py:2: DtypeWarning: Columns (4,11,12,16,17,18,19,20,40,41,42,43,44,45,52,53,54,55,56,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,108,110) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dataset = pd.read_csv(\"SpeedDating.csv\", index_col=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    gender   age  age_o  importance_same_race  importance_same_religion  \\\n",
      "id                                                                        \n",
      "1      1.0  21.0   27.0                   2.0                       4.0   \n",
      "2      1.0  21.0   22.0                   2.0                       4.0   \n",
      "3      1.0  21.0   22.0                   2.0                       4.0   \n",
      "4      1.0  21.0   23.0                   2.0                       4.0   \n",
      "5      1.0  21.0   24.0                   2.0                       4.0   \n",
      "\n",
      "    pref_o_attractive  pref_o_sincere  pref_o_intelligence  pref_o_funny  \\\n",
      "id                                                                         \n",
      "1                35.0            20.0                 20.0          20.0   \n",
      "2                60.0             0.0                  0.0          40.0   \n",
      "3                19.0            18.0                 19.0          18.0   \n",
      "4                30.0             5.0                 15.0          40.0   \n",
      "5                30.0            10.0                 20.0          10.0   \n",
      "\n",
      "    pref_o_ambitious  ...  race_Black/African American  \\\n",
      "id                    ...                                \n",
      "1                0.0  ...                          0.0   \n",
      "2                0.0  ...                          0.0   \n",
      "3               14.0  ...                          0.0   \n",
      "4                5.0  ...                          0.0   \n",
      "5               10.0  ...                          0.0   \n",
      "\n",
      "    race_European/Caucasian-American  race_Latino/Hispanic American  \\\n",
      "id                                                                    \n",
      "1                                0.0                            0.0   \n",
      "2                                0.0                            0.0   \n",
      "3                                0.0                            0.0   \n",
      "4                                0.0                            0.0   \n",
      "5                                0.0                            0.0   \n",
      "\n",
      "    race_Other  race_o_?  race_o_Asian/Pacific Islander/Asian-American  \\\n",
      "id                                                                       \n",
      "1          0.0       0.0                                           0.0   \n",
      "2          0.0       0.0                                           0.0   \n",
      "3          0.0       0.0                                           1.0   \n",
      "4          0.0       0.0                                           0.0   \n",
      "5          0.0       0.0                                           0.0   \n",
      "\n",
      "    race_o_Black/African American  race_o_European/Caucasian-American  \\\n",
      "id                                                                      \n",
      "1                             0.0                                 1.0   \n",
      "2                             0.0                                 1.0   \n",
      "3                             0.0                                 0.0   \n",
      "4                             0.0                                 1.0   \n",
      "5                             0.0                                 0.0   \n",
      "\n",
      "    race_o_Latino/Hispanic American  race_o_Other  \n",
      "id                                                 \n",
      "1                               0.0           0.0  \n",
      "2                               0.0           0.0  \n",
      "3                               0.0           0.0  \n",
      "4                               0.0           0.0  \n",
      "5                               1.0           0.0  \n",
      "\n",
      "[5 rows x 70 columns]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T17:58:20.768281Z",
     "start_time": "2025-02-01T17:58:20.754319Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_test_models(models, hyperparameters, X, y, path, limit):\n",
    "    accuracies = {}\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=SEED)\n",
    "    if not Path(path).is_file():\n",
    "        with open(path, 'w', newline='') as csvfile:\n",
    "            fieldnames = ['model_class', 'acc', 'kwargs']\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "    for model_class in models:\n",
    "        model_hyperparameters = hyperparameters[model_class.__name__]\n",
    "        accuracies[model_class.__name__] = []\n",
    "        for hyperparams in tqdm(product(*model_hyperparameters.values())):\n",
    "            kwargs = dict(zip(model_hyperparameters.keys(), hyperparams))\n",
    "            if model_class.__name__ == 'SVMClassifier':\n",
    "                if kwargs['kernel'] != 'poly' and kwargs['degree'] != 3:\n",
    "                    continue\n",
    "            model = model_class(**kwargs)\n",
    "            try:\n",
    "                with time_limit(limit):\n",
    "                    model.fit(X_train, y_train)\n",
    "                acc = np.mean(model.predict(X_test) == np.array(y_test))\n",
    "                accuracies[model_class.__name__].append((acc, kwargs))\n",
    "                with open(path, 'a', newline='') as csvfile:\n",
    "                    writer = csv.writer(csvfile)\n",
    "                    writer.writerows([[model_class.__name__, acc, kwargs]])\n",
    "            except TimeoutException as e:\n",
    "                with open(path, 'a', newline='') as csvfile:\n",
    "                    writer = csv.writer(csvfile)\n",
    "                    writer.writerows([[model_class.__name__, 'EXCEEDED', kwargs]])\n",
    "    return accuracies"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T17:58:20.830116Z",
     "start_time": "2025-02-01T17:58:20.817151Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def cross_validate_models(models, kwargs_lists, X, y, path, limit):\n",
    "    accuracies = {}\n",
    "    kf = StratifiedKFold(n_splits=NUM_SPLITS, shuffle=True, random_state=SEED)\n",
    "    if not Path(path).is_file():\n",
    "        with open(path, 'w', newline='') as csvfile:\n",
    "            fieldnames = ['model_class', 'acc', 'kwargs']\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "    for model_class in models:\n",
    "        accuracies[model_class.__name__] = []\n",
    "        for kwargs in tqdm(kwargs_lists[model_class.__name__]):\n",
    "            s=0\n",
    "            model = model_class(**kwargs)\n",
    "            try:\n",
    "                for train_idx, test_idx in kf.split(X, y):\n",
    "                    X_train, y_train = X.iloc[train_idx, :], y.iloc[train_idx]\n",
    "                    X_test, y_test = X.iloc[test_idx, :], y.iloc[test_idx]\n",
    "                    with time_limit(limit):\n",
    "                        model.fit(X_train, y_train)\n",
    "                    s += np.mean(model.predict(X_test) == np.array(y_test))\n",
    "                accuracies[model_class.__name__].append((s/NUM_SPLITS, kwargs))\n",
    "                with open(path, 'a', newline='') as csvfile:\n",
    "                    writer = csv.writer(csvfile)\n",
    "                    writer.writerows([[model_class.__name__, acc, kwargs]])\n",
    "            except TimeoutException as e:\n",
    "                with open(path, 'a', newline='') as csvfile:\n",
    "                    writer = csv.writer(csvfile)\n",
    "                    writer.writerows([[model_class.__name__, 'EXCEEDED', kwargs]])\n",
    "    return accuracies"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T17:58:26.192733Z",
     "start_time": "2025-02-01T17:58:26.180766Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_top_kwargs(models, accuracies, cutoff):\n",
    "    top_kwargs = {}\n",
    "    for model_class in models:\n",
    "        _, top_models_ = zip(*(sorted(accuracies[model_class.__name__], key=lambda x: x[0])[-int(cutoff*len(accuracies[model_class.__name__])):]))\n",
    "        top_kwargs[model_class.__name__] = list(top_models_)\n",
    "    return top_kwargs"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T17:58:28.589958Z",
     "start_time": "2025-02-01T17:58:28.580983Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_rashomon_sets(models, hyperparameters, X, y, initial_cutoff, top, initial_path=MODEL_ACCURACIES_PATH,\n",
    "                      cross_validation_path=FILTERED_MODEL_ACCURACIES_PATH, initial_time_limit=TIME_LIMIT,\n",
    "                      cross_validation_time_limit=TIME_LIMIT_CROSS_VALIDATION):\n",
    "    assert top <= initial_cutoff\n",
    "    initial_accuracies = train_test_models(models, hyperparameters, X, y, path=initial_path, limit=initial_time_limit)\n",
    "    filtered_kwargs_lists = get_top_kwargs(models, initial_accuracies, initial_cutoff)\n",
    "    final_accuracies = cross_validate_models(models, filtered_kwargs_lists, X, y, path=cross_validation_path,\n",
    "                                             limit=cross_validation_time_limit)\n",
    "    top_kwargs = get_top_kwargs(models, final_accuracies, top/initial_cutoff)\n",
    "    return top_kwargs"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T17:58:33.075145Z",
     "start_time": "2025-02-01T17:58:31.430569Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rashomon_sets_params = get_rashomon_sets(MODELS, HYPERPARAMETERS, X, y, INITIAL_CUTOFF, TOP)\n",
    "pickle.dump(rashomon_sets_params, open('rashomon_sets_params.pickle', 'wb'))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'signal' has no attribute 'SIGALRM'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m rashomon_sets_params \u001B[38;5;241m=\u001B[39m \u001B[43mget_rashomon_sets\u001B[49m\u001B[43m(\u001B[49m\u001B[43mMODELS\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mHYPERPARAMETERS\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mINITIAL_CUTOFF\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mTOP\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m pickle\u001B[38;5;241m.\u001B[39mdump(rashomon_sets_params, \u001B[38;5;28mopen\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrashomon_sets_params.pickle\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwb\u001B[39m\u001B[38;5;124m'\u001B[39m))\n",
      "Cell \u001B[1;32mIn[11], line 5\u001B[0m, in \u001B[0;36mget_rashomon_sets\u001B[1;34m(models, hyperparameters, X, y, initial_cutoff, top, initial_path, cross_validation_path, initial_time_limit, cross_validation_time_limit)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_rashomon_sets\u001B[39m(models, hyperparameters, X, y, initial_cutoff, top, initial_path\u001B[38;5;241m=\u001B[39mMODEL_ACCURACIES_PATH,\n\u001B[0;32m      2\u001B[0m                       cross_validation_path\u001B[38;5;241m=\u001B[39mFILTERED_MODEL_ACCURACIES_PATH, initial_time_limit\u001B[38;5;241m=\u001B[39mTIME_LIMIT,\n\u001B[0;32m      3\u001B[0m                       cross_validation_time_limit\u001B[38;5;241m=\u001B[39mTIME_LIMIT_CROSS_VALIDATION):\n\u001B[0;32m      4\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m top \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m initial_cutoff\n\u001B[1;32m----> 5\u001B[0m     initial_accuracies \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_test_models\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhyperparameters\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minitial_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlimit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minitial_time_limit\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      6\u001B[0m     filtered_kwargs_lists \u001B[38;5;241m=\u001B[39m get_top_kwargs(models, initial_accuracies, initial_cutoff)\n\u001B[0;32m      7\u001B[0m     final_accuracies \u001B[38;5;241m=\u001B[39m cross_validate_models(models, filtered_kwargs_lists, X, y, path\u001B[38;5;241m=\u001B[39mcross_validation_path,\n\u001B[0;32m      8\u001B[0m                                              limit\u001B[38;5;241m=\u001B[39mcross_validation_time_limit)\n",
      "Cell \u001B[1;32mIn[8], line 19\u001B[0m, in \u001B[0;36mtrain_test_models\u001B[1;34m(models, hyperparameters, X, y, path, limit)\u001B[0m\n\u001B[0;32m     17\u001B[0m model \u001B[38;5;241m=\u001B[39m model_class(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 19\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m time_limit(limit):\n\u001B[0;32m     20\u001B[0m         model\u001B[38;5;241m.\u001B[39mfit(X_train, y_train)\n\u001B[0;32m     21\u001B[0m     acc \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmean(model\u001B[38;5;241m.\u001B[39mpredict(X_test) \u001B[38;5;241m==\u001B[39m np\u001B[38;5;241m.\u001B[39marray(y_test))\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\contextlib.py:135\u001B[0m, in \u001B[0;36m_GeneratorContextManager.__enter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    133\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkwds, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunc\n\u001B[0;32m    134\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 135\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgen\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    136\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m:\n\u001B[0;32m    137\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgenerator didn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt yield\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[2], line 10\u001B[0m, in \u001B[0;36mtime_limit\u001B[1;34m(seconds)\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msignal_handler\u001B[39m(signum, frame):\n\u001B[0;32m      9\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m TimeoutException(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTimed out!\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 10\u001B[0m signal\u001B[38;5;241m.\u001B[39msignal(\u001B[43msignal\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mSIGALRM\u001B[49m, signal_handler)\n\u001B[0;32m     11\u001B[0m signal\u001B[38;5;241m.\u001B[39malarm(seconds)\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[1;31mAttributeError\u001B[0m: module 'signal' has no attribute 'SIGALRM'"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# rashomon_sets_params = pickle.load(open('rashomon_sets_params.pickle', 'rb'))",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=(SEED+1))\n",
    "rashomon_sets = {}\n",
    "rashomon_sets_acc_lower_bounds = {}\n",
    "accuracies = {}\n",
    "for model_class in MODELS:\n",
    "    rashomon_sets[model_class.__name__] = []\n",
    "    accuracies[model_class.__name__] = []\n",
    "    for kwargs in rashomon_sets_params[model_class.__name__]:\n",
    "        if model_class.__name__ == 'SVMClassifier':\n",
    "            model = model_class(probability=True, **kwargs)\n",
    "        else:\n",
    "            model = model_class(**kwargs)\n",
    "        model.fit(X_train, y_train)\n",
    "        acc = np.mean(model.predict(X_test) == np.array(y_test))\n",
    "        accuracies[model_class.__name__].append(acc)\n",
    "        rashomon_sets[model_class.__name__].append(model)\n",
    "    rashomon_sets_acc_lower_bounds[model_class.__name__] = min(accuracies[model_class.__name__])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Compare accuracies for different Rashomon sets\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.title(\"Rashomon set accuracy comparison between different model classes\")\n",
    "plt.axhline(BASELINE, color='black', linestyle='--', linewidth=1, label='baseline')\n",
    "plt.xlabel('model class')\n",
    "plt.ylabel('accuracy')\n",
    "plt.boxplot([accuracies[model_class.__name__] for model_class in MODELS])\n",
    "plt.xticks(np.arange(1, 1+len(MODELS)), [model_class.__name__ for model_class in MODELS])\n",
    "plt.legend()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "INDICES = [42, 123, 314]\n",
    "RANDOM_SAMPLES = [X_test.iloc[i, :] for i in INDICES]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Permutation feature importance\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    for model_class in MODELS:\n",
    "        for model in rashomon_sets[model_class.__name__]:\n",
    "            importances = permutation_importance(model, X_test, y_test,\n",
    "                           n_repeats=1,\n",
    "                           random_state=SEED,\n",
    "                            scoring=\"accuracy\")\n",
    "            importances = pd.Series(importances['importances'][:, 0], index=list(X.columns))\n",
    "            fig, ax = plt.subplots()\n",
    "            importances.plot.bar(ax=ax)\n",
    "            ax.set_title(\"Permutation feature importances\")\n",
    "            ax.set_ylabel(\"importance\")\n",
    "            fig.tight_layout()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for model_class in MODELS:\n",
    "    print(len(rashomon_sets[model_class.__name__]))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# LIME\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    categorical_features = [0, 3, 4, -1]\n",
    "    lime_explainer = lime.lime_tabular.LimeTabularExplainer(X.to_numpy(), categorical_features=categorical_features, feature_names=list(X.columns), class_names=['negative', 'positive'])\n",
    "    for model_class in MODELS:\n",
    "        for model in rashomon_sets[model_class.__name__]:\n",
    "            explaination = lime_explainer.explain_instance(X_test.iloc[SEED, :], model.predict_proba, num_features=5)\n",
    "            fig = explaination.as_pyplot_figure()\n",
    "            plt.plot()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Shap\n",
    "i = 0\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    for model_class in MODELS:\n",
    "        for model in rashomon_sets[model_class.__name__]:\n",
    "            i += 1\n",
    "            if i <= 4:\n",
    "                continue\n",
    "            # if hasattr(model, \"feature_names_in_\"):\n",
    "            # model.fit(X_train.values, y_train.values)\n",
    "            print(type(X_train.iloc[:100, :]))\n",
    "            shap_explainer = shap.KernelExplainer(model.predict, X_train.iloc[:100, :].to_numpy(), feature_names=list(X.columns))\n",
    "            explaination = shap_explainer(X_test.iloc[[SEED], :])\n",
    "            shap_values = explaination.values\n",
    "            shap.plots.beeswarm(explaination)\n",
    "            plt.plot()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
