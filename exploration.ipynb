{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler # To preprocess data for SVM - greatly improves performance\n",
    "from sklearn.svm import SVC\n",
    "from typing import Tuple\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "id": "mzX1wFJAONFQ",
    "ExecuteTime": {
     "end_time": "2025-01-23T00:17:29.062756Z",
     "start_time": "2025-01-23T00:17:27.067365Z"
    }
   },
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "# constants\n",
    "SEED = 42\n",
    "NUM_SPLITS = 10\n",
    "TARGET = \"decision\""
   ],
   "metadata": {
    "id": "r4lGdgRVRMM5",
    "ExecuteTime": {
     "end_time": "2025-01-23T00:17:31.133206Z",
     "start_time": "2025-01-23T00:17:31.114260Z"
    }
   },
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "def one_hot_encode(df, features):\n",
    "    for feature in features:\n",
    "        dummies = pd.get_dummies(df.loc[:, feature], prefix=feature)\n",
    "        df = pd.concat([df, dummies], axis=1)\n",
    "        df = df.drop(feature, axis=1)\n",
    "    return df"
   ],
   "metadata": {
    "id": "1dy8AeieTKI2",
    "ExecuteTime": {
     "end_time": "2025-01-23T00:17:34.937942Z",
     "start_time": "2025-01-23T00:17:34.917943Z"
    }
   },
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iGaslg9IB3oc",
    "outputId": "7eeb95d1-73ae-4231-9873-3c6bd3956e8e",
    "ExecuteTime": {
     "end_time": "2025-01-23T00:17:40.230775Z",
     "start_time": "2025-01-23T00:17:37.486246Z"
    }
   },
   "source": [
    "# load dataset\n",
    "dataset = pd.read_csv(\"SpeedDating.csv\", index_col=0)\n",
    "\n",
    "# remove redundant columns\n",
    "subset = ['gender', 'age', 'age_o', 'race', 'race_o', 'importance_same_race', 'importance_same_religion',\n",
    "          'pref_o_attractive', 'pref_o_sincere', 'pref_o_intelligence',\n",
    "          'pref_o_funny', 'pref_o_ambitious', 'pref_o_shared_interests', 'attractive_o', 'sinsere_o', 'intelligence_o', 'funny_o',\n",
    "          'ambitous_o', 'shared_interests_o', 'attractive_important', 'sincere_important', 'intellicence_important', 'funny_important', 'ambtition_important',\n",
    "          'shared_interests_important', 'attractive', 'sincere', 'intelligence', 'funny', 'ambition', 'attractive_partner', 'sincere_partner',\n",
    "          'intelligence_partner', 'funny_partner', 'ambition_partner', 'shared_interests_partner',\n",
    "          'sports', 'tvsports', 'exercise', 'dining', 'museums', 'art', 'hiking', 'gaming', 'clubbing', 'reading', 'tv', 'theater', 'movies', 'concerts',\n",
    "          'music', 'shopping', 'yoga',\n",
    "          'interests_correlate', 'expected_happy_with_sd_people', 'expected_num_matches', 'expected_num_interested_in_me',\n",
    "          'like', 'guess_prob_liked', 'decision']\n",
    "\n",
    "dataset = dataset.loc[:, subset]\n",
    "dataset.loc[:, 'gender'] = (dataset.loc[:, 'gender'] == 'female') # one hot encode gender\n",
    "dataset = one_hot_encode(dataset, ['race', 'race_o'])\n",
    "dataset = dataset.apply(pd.to_numeric, errors='coerce', axis=1)\n",
    "dataset = dataset.fillna(dataset.mean())\n",
    "print(dataset.head())\n",
    "X, y = dataset.loc[:, dataset.columns != TARGET], dataset.loc[:, TARGET]\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mracz\\AppData\\Local\\Temp\\ipykernel_7204\\2693588946.py:2: DtypeWarning: Columns (4,11,12,16,17,18,19,20,40,41,42,43,44,45,52,53,54,55,56,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,108,110) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dataset = pd.read_csv(\"SpeedDating.csv\", index_col=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    gender   age  age_o  importance_same_race  importance_same_religion  \\\n",
      "id                                                                        \n",
      "1      1.0  21.0   27.0                   2.0                       4.0   \n",
      "2      1.0  21.0   22.0                   2.0                       4.0   \n",
      "3      1.0  21.0   22.0                   2.0                       4.0   \n",
      "4      1.0  21.0   23.0                   2.0                       4.0   \n",
      "5      1.0  21.0   24.0                   2.0                       4.0   \n",
      "\n",
      "    pref_o_attractive  pref_o_sincere  pref_o_intelligence  pref_o_funny  \\\n",
      "id                                                                         \n",
      "1                35.0            20.0                 20.0          20.0   \n",
      "2                60.0             0.0                  0.0          40.0   \n",
      "3                19.0            18.0                 19.0          18.0   \n",
      "4                30.0             5.0                 15.0          40.0   \n",
      "5                30.0            10.0                 20.0          10.0   \n",
      "\n",
      "    pref_o_ambitious  ...  race_Black/African American  \\\n",
      "id                    ...                                \n",
      "1                0.0  ...                          0.0   \n",
      "2                0.0  ...                          0.0   \n",
      "3               14.0  ...                          0.0   \n",
      "4                5.0  ...                          0.0   \n",
      "5               10.0  ...                          0.0   \n",
      "\n",
      "    race_European/Caucasian-American  race_Latino/Hispanic American  \\\n",
      "id                                                                    \n",
      "1                                0.0                            0.0   \n",
      "2                                0.0                            0.0   \n",
      "3                                0.0                            0.0   \n",
      "4                                0.0                            0.0   \n",
      "5                                0.0                            0.0   \n",
      "\n",
      "    race_Other  race_o_?  race_o_Asian/Pacific Islander/Asian-American  \\\n",
      "id                                                                       \n",
      "1          0.0       0.0                                           0.0   \n",
      "2          0.0       0.0                                           0.0   \n",
      "3          0.0       0.0                                           1.0   \n",
      "4          0.0       0.0                                           0.0   \n",
      "5          0.0       0.0                                           0.0   \n",
      "\n",
      "    race_o_Black/African American  race_o_European/Caucasian-American  \\\n",
      "id                                                                      \n",
      "1                             0.0                                 1.0   \n",
      "2                             0.0                                 1.0   \n",
      "3                             0.0                                 0.0   \n",
      "4                             0.0                                 1.0   \n",
      "5                             0.0                                 0.0   \n",
      "\n",
      "    race_o_Latino/Hispanic American  race_o_Other  \n",
      "id                                                 \n",
      "1                               0.0           0.0  \n",
      "2                               0.0           0.0  \n",
      "3                               0.0           0.0  \n",
      "4                               0.0           0.0  \n",
      "5                               1.0           0.0  \n",
      "\n",
      "[5 rows x 70 columns]\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T00:20:26.696595Z",
     "start_time": "2025-01-23T00:19:48.428119Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train and test the model\n",
    "kf = StratifiedKFold(n_splits=NUM_SPLITS, shuffle=True, random_state=SEED)\n",
    "svm_classifier = make_pipeline(StandardScaler(), SVC())\n",
    "s=0\n",
    "for train_idx, test_idx in kf.split(X, y):\n",
    "    X_train, y_train = X.iloc[train_idx, :], y.iloc[train_idx]\n",
    "    X_test, y_test = X.iloc[test_idx, :], y.iloc[test_idx]\n",
    "    svm_classifier.fit(X_train, y_train)\n",
    "    print('Split accuracy: ', np.mean(svm_classifier.predict(X_test) == np.array(y_test)))\n",
    "    s += np.mean(svm_classifier.predict(X_test) == np.array(y_test))\n",
    "    print('Accuracy for class 1 [person wanted to match]', np.sum( np.logical_and(svm_classifier.predict(X_test) == 1, svm_classifier.predict(X_test) == y_test))/np.sum(y_test))\n",
    "print('Average accuracy:')\n",
    "print(s/NUM_SPLITS)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split accuracy:  0.8245823389021479\n",
      "Accuracy for class 1 [person wanted to match] 0.7698863636363636\n",
      "Split accuracy:  0.8317422434367542\n",
      "Accuracy for class 1 [person wanted to match] 0.7840909090909091\n",
      "Split accuracy:  0.8389021479713604\n",
      "Accuracy for class 1 [person wanted to match] 0.8494318181818182\n",
      "Split accuracy:  0.863961813842482\n",
      "Accuracy for class 1 [person wanted to match] 0.8409090909090909\n",
      "Split accuracy:  0.8257756563245824\n",
      "Accuracy for class 1 [person wanted to match] 0.7698863636363636\n",
      "Split accuracy:  0.8520286396181385\n",
      "Accuracy for class 1 [person wanted to match] 0.8210227272727273\n",
      "Split accuracy:  0.837708830548926\n",
      "Accuracy for class 1 [person wanted to match] 0.8039772727272727\n",
      "Split accuracy:  0.8365155131264916\n",
      "Accuracy for class 1 [person wanted to match] 0.8125\n",
      "Split accuracy:  0.8351254480286738\n",
      "Accuracy for class 1 [person wanted to match] 0.7692307692307693\n",
      "Split accuracy:  0.8315412186379928\n",
      "Accuracy for class 1 [person wanted to match] 0.8062678062678063\n",
      "Average accuracy:\n",
      "0.8377883850437551\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "source": [
    "# Train and test the model\n",
    "kf = StratifiedKFold(n_splits=NUM_SPLITS, shuffle=True, random_state=SEED)\n",
    "xgboost = XGBClassifier(max_depth=4)\n",
    "s=0\n",
    "for train_idx, test_idx in kf.split(X, y):\n",
    "    X_train, y_train = X.iloc[train_idx, :], y.iloc[train_idx]\n",
    "    X_test, y_test = X.iloc[test_idx, :], y.iloc[test_idx]\n",
    "    xgboost.fit(X_train, y_train)\n",
    "    print('Split accuracy: ', np.mean(xgboost.predict(X_test) == np.array(y_test)))\n",
    "    s += np.mean(xgboost.predict(X_test) == np.array(y_test))\n",
    "    print('Accuracy for class 1 [person wanted to match]', np.sum( np.logical_and(xgboost.predict(X_test) == 1, xgboost.predict(X_test) == y_test))/np.sum(y_test))\n",
    "print('Average accuracy:')\n",
    "print(s/NUM_SPLITS)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rQ4qjuXWVooN",
    "outputId": "57b88f4f-f199-4adb-b77d-d6ab90dc5f8d"
   },
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Split accuracy:  0.8317422434367542\n",
      "Accuracy for class 1 [person wanted to match] 0.7840909090909091\n",
      "Split accuracy:  0.8663484486873508\n",
      "Accuracy for class 1 [person wanted to match] 0.8465909090909091\n",
      "Split accuracy:  0.8400954653937948\n",
      "Accuracy for class 1 [person wanted to match] 0.8153409090909091\n",
      "Split accuracy:  0.8591885441527446\n",
      "Accuracy for class 1 [person wanted to match] 0.8238636363636364\n",
      "Split accuracy:  0.8400954653937948\n",
      "Accuracy for class 1 [person wanted to match] 0.7897727272727273\n",
      "Split accuracy:  0.8651551312649165\n",
      "Accuracy for class 1 [person wanted to match] 0.8323863636363636\n",
      "Split accuracy:  0.8400954653937948\n",
      "Accuracy for class 1 [person wanted to match] 0.7982954545454546\n",
      "Split accuracy:  0.8448687350835322\n",
      "Accuracy for class 1 [person wanted to match] 0.8068181818181818\n",
      "Split accuracy:  0.8482676224611708\n",
      "Accuracy for class 1 [person wanted to match] 0.792022792022792\n",
      "Split accuracy:  0.8327359617682198\n",
      "Accuracy for class 1 [person wanted to match] 0.8176638176638177\n",
      "Average accuracy:\n",
      "0.8468593083036072\n"
     ]
    }
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
